import {TokenType} from "../../enums/tokenType";
import {TokenizerGrammar} from "../tokenizerGrammar";
import {SingleTokenConfig} from "../types/singleTokenConfig";
import {KeywordConfig} from "../types/keywordConfig";
import {WhitespaceConfig} from "../types/whitespaceConfig";

const singleTokens: SingleTokenConfig = {
    "(": TokenType.L_PAREN,
    ")": TokenType.R_PAREN,
    "[": TokenType.L_BRACKET,
    "]": TokenType.R_BRACKET,
    "{": TokenType.L_BRACE,
    "}": TokenType.R_BRACE,
    "&": TokenType.AMP,
    "^": TokenType.CARET,
    ":": TokenType.COLON,
    ",": TokenType.COMMA,
    ".": TokenType.DOT,
    "-": TokenType.DASH,
    "=": TokenType.EQ,
    ">": TokenType.GT,
    "<": TokenType.LT,
    "%": TokenType.MOD,
    "!": TokenType.NOT,
    "|": TokenType.PIPE,
    "+": TokenType.PLUS,
    ";": TokenType.SEMICOLON,
    "/": TokenType.SLASH,
    "\\": TokenType.BACKSLASH,
    "*": TokenType.STAR,
    "~": TokenType.TILDA,
    "?": TokenType.PLACEHOLDER,
    "@": TokenType.PARAMETER,
    "'": TokenType.QUOTE,
    "`": TokenType.IDENTIFIER,
    '"': TokenType.IDENTIFIER,
    "#": TokenType.HASH,
};

const postfixes = ["", "+", "-"]
const prefixes = ["", "+", "-"]

const keywords: KeywordConfig = {
    ...postfixes.reduce((postfixKeys, postfix) => ({
        ...postfixKeys,
        [`{%${postfix}`]: TokenType.BLOCK_START,
    }), {}),
    ...prefixes.reduce((prefixKeys, prefix) => ({
        ...prefixKeys,
        [`${prefix}%}`]: TokenType.BLOCK_END,
    }), {}),
    ...postfixes.filter(Boolean).reduce((postfixKeys, postfix) => ({
        ...postfixKeys,
        [`{{${postfix}`]: TokenType.BLOCK_START,
    }), {}),
    ...prefixes.filter(Boolean).reduce((prefixKeys, prefix) => ({
        ...prefixKeys,
        [`${prefix}}}`]: TokenType.BLOCK_END,
    }), {}),
    "/*+": TokenType.HINT,
    "==": TokenType.EQ,
    "::": TokenType.DCOLON,
    "||": TokenType.DPIPE,
    ">=": TokenType.GTE,
    "<=": TokenType.LTE,
    "<>": TokenType.NEQ,
    "!=": TokenType.NEQ,
    "<=>": TokenType.NULLSAFE_EQ,
    "->": TokenType.ARROW,
    "->>": TokenType.DARROW,
    "=>": TokenType.FARROW,
    "#>": TokenType.HASH_ARROW,
    "#>>": TokenType.DHASH_ARROW,
    "<->": TokenType.LR_ARROW,
    "&&": TokenType.DAMP,
    "ALL": TokenType.ALL,
    "ALWAYS": TokenType.ALWAYS,
    "AND": TokenType.AND,
    "ANTI": TokenType.ANTI,
    "ANY": TokenType.ANY,
    "ASC": TokenType.ASC,
    "AS": TokenType.ALIAS,
    "ASOF": TokenType.ASOF,
    "AUTOINCREMENT": TokenType.AUTO_INCREMENT,
    "AUTO_INCREMENT": TokenType.AUTO_INCREMENT,
    "BEGIN": TokenType.BEGIN,
    "BETWEEN": TokenType.BETWEEN,
    "CACHE": TokenType.CACHE,
    "UNCACHE": TokenType.UNCACHE,
    "CASE": TokenType.CASE,
    "CHARACTER SET": TokenType.CHARACTER_SET,
    "CLUSTER BY": TokenType.CLUSTER_BY,
    "COLLATE": TokenType.COLLATE,
    "COLUMN": TokenType.COLUMN,
    "COMMIT": TokenType.COMMIT,
    "CONSTRAINT": TokenType.CONSTRAINT,
    "CREATE": TokenType.CREATE,
    "CROSS": TokenType.CROSS,
    "CUBE": TokenType.CUBE,
    "CURRENT_DATE": TokenType.CURRENT_DATE,
    "CURRENT_TIME": TokenType.CURRENT_TIME,
    "CURRENT_TIMESTAMP": TokenType.CURRENT_TIMESTAMP,
    "CURRENT_USER": TokenType.CURRENT_USER,
    "DATABASE": TokenType.DATABASE,
    "DEFAULT": TokenType.DEFAULT,
    "DELETE": TokenType.DELETE,
    "DESC": TokenType.DESC,
    "DESCRIBE": TokenType.DESCRIBE,
    "DISTINCT": TokenType.DISTINCT,
    "DISTRIBUTE BY": TokenType.DISTRIBUTE_BY,
    "DIV": TokenType.DIV,
    "DROP": TokenType.DROP,
    "ELSE": TokenType.ELSE,
    "END": TokenType.END,
    "ESCAPE": TokenType.ESCAPE,
    "EXCEPT": TokenType.EXCEPT,
    "EXECUTE": TokenType.EXECUTE,
    "EXISTS": TokenType.EXISTS,
    "FALSE": TokenType.FALSE,
    "FETCH": TokenType.FETCH,
    "FILTER": TokenType.FILTER,
    "FIRST": TokenType.FIRST,
    "FULL": TokenType.FULL,
    "FUNCTION": TokenType.FUNCTION,
    "FOR": TokenType.FOR,
    "FOREIGN KEY": TokenType.FOREIGN_KEY,
    "FORMAT": TokenType.FORMAT,
    "FROM": TokenType.FROM,
    "GEOGRAPHY": TokenType.GEOGRAPHY,
    "GEOMETRY": TokenType.GEOMETRY,
    "GLOB": TokenType.GLOB,
    "GROUP BY": TokenType.GROUP_BY,
    "GROUPING SETS": TokenType.GROUPING_SETS,
    "HAVING": TokenType.HAVING,
    "IF": TokenType.IF,
    "ILIKE": TokenType.ILIKE,
    "IN": TokenType.IN,
    "INDEX": TokenType.INDEX,
    "INET": TokenType.INET,
    "INNER": TokenType.INNER,
    "INSERT": TokenType.INSERT,
    "INTERVAL": TokenType.INTERVAL,
    "INTERSECT": TokenType.INTERSECT,
    "INTO": TokenType.INTO,
    "IS": TokenType.IS,
    "ISNULL": TokenType.ISNULL,
    "JOIN": TokenType.JOIN,
    "KEEP": TokenType.KEEP,
    "LATERAL": TokenType.LATERAL,
    "LEFT": TokenType.LEFT,
    "LIKE": TokenType.LIKE,
    "LIMIT": TokenType.LIMIT,
    "LOAD": TokenType.LOAD,
    "LOCK": TokenType.LOCK,
    "MERGE": TokenType.MERGE,
    "NATURAL": TokenType.NATURAL,
    "NEXT": TokenType.NEXT,
    "NEXT VALUE FOR": TokenType.NEXT_VALUE_FOR,
    "NOT": TokenType.NOT,
    "NOTNULL": TokenType.NOTNULL,
    "NULL": TokenType.NULL,
    "OBJECT": TokenType.OBJECT,
    "OFFSET": TokenType.OFFSET,
    "ON": TokenType.ON,
    "OR": TokenType.OR,
    "ORDER BY": TokenType.ORDER_BY,
    "ORDINALITY": TokenType.ORDINALITY,
    "OUTER": TokenType.OUTER,
    "OVER": TokenType.OVER,
    "OVERLAPS": TokenType.OVERLAPS,
    "OVERWRITE": TokenType.OVERWRITE,
    "PARTITION": TokenType.PARTITION,
    "PARTITION BY": TokenType.PARTITION_BY,
    "PARTITIONED BY": TokenType.PARTITION_BY,
    "PARTITIONED_BY": TokenType.PARTITION_BY,
    "PERCENT": TokenType.PERCENT,
    "PIVOT": TokenType.PIVOT,
    "PRAGMA": TokenType.PRAGMA,
    "PRIMARY KEY": TokenType.PRIMARY_KEY,
    "PROCEDURE": TokenType.PROCEDURE,
    "QUALIFY": TokenType.QUALIFY,
    "RANGE": TokenType.RANGE,
    "RECURSIVE": TokenType.RECURSIVE,
    "REGEXP": TokenType.RLIKE,
    "REPLACE": TokenType.REPLACE,
    "RETURNING": TokenType.RETURNING,
    "REFERENCES": TokenType.REFERENCES,
    "RIGHT": TokenType.RIGHT,
    "RLIKE": TokenType.RLIKE,
    "ROLLBACK": TokenType.ROLLBACK,
    "ROLLUP": TokenType.ROLLUP,
    "ROW": TokenType.ROW,
    "ROWS": TokenType.ROWS,
    "SCHEMA": TokenType.SCHEMA,
    "SELECT": TokenType.SELECT,
    "SEMI": TokenType.SEMI,
    "SET": TokenType.SET,
    "SETTINGS": TokenType.SETTINGS,
    "SHOW": TokenType.SHOW,
    "SIMILAR TO": TokenType.SIMILAR_TO,
    "SOME": TokenType.SOME,
    "SORT BY": TokenType.SORT_BY,
    "TABLE": TokenType.TABLE,
    "TABLESAMPLE": TokenType.TABLE_SAMPLE,
    "TEMP": TokenType.TEMPORARY,
    "TEMPORARY": TokenType.TEMPORARY,
    "THEN": TokenType.THEN,
    "TRUE": TokenType.TRUE,
    "UNION": TokenType.UNION,
    "UNNEST": TokenType.UNNEST,
    "UNPIVOT": TokenType.UNPIVOT,
    "UPDATE": TokenType.UPDATE,
    "USE": TokenType.USE,
    "USING": TokenType.USING,
    "UUID": TokenType.UUID,
    "VALUES": TokenType.VALUES,
    "VIEW": TokenType.VIEW,
    "VOLATILE": TokenType.VOLATILE,
    "WHEN": TokenType.WHEN,
    "WHERE": TokenType.WHERE,
    "WINDOW": TokenType.WINDOW,
    "WITH": TokenType.WITH,
    "APPLY": TokenType.APPLY,
    "ARRAY": TokenType.ARRAY,
    "BIT": TokenType.BIT,
    "BOOL": TokenType.BOOLEAN,
    "BOOLEAN": TokenType.BOOLEAN,
    "BYTE": TokenType.TINYINT,
    "TINYINT": TokenType.TINYINT,
    "SHORT": TokenType.SMALLINT,
    "SMALLINT": TokenType.SMALLINT,
    "INT2": TokenType.SMALLINT,
    "INTEGER": TokenType.INT,
    "INT": TokenType.INT,
    "INT4": TokenType.INT,
    "LONG": TokenType.BIGINT,
    "BIGINT": TokenType.BIGINT,
    "INT8": TokenType.BIGINT,
    "DEC": TokenType.DECIMAL,
    "DECIMAL": TokenType.DECIMAL,
    "BIGDECIMAL": TokenType.BIGDECIMAL,
    "BIGNUMERIC": TokenType.BIGDECIMAL,
    "MAP": TokenType.MAP,
    "NULLABLE": TokenType.NULLABLE,
    "NUMBER": TokenType.DECIMAL,
    "NUMERIC": TokenType.DECIMAL,
    "FIXED": TokenType.DECIMAL,
    "REAL": TokenType.FLOAT,
    "FLOAT": TokenType.FLOAT,
    "FLOAT4": TokenType.FLOAT,
    "FLOAT8": TokenType.DOUBLE,
    "DOUBLE": TokenType.DOUBLE,
    "DOUBLE PRECISION": TokenType.DOUBLE,
    "JSON": TokenType.JSON,
    "CHAR": TokenType.CHAR,
    "CHARACTER": TokenType.CHAR,
    "NCHAR": TokenType.NCHAR,
    "VARCHAR": TokenType.VARCHAR,
    "VARCHAR2": TokenType.VARCHAR,
    "NVARCHAR": TokenType.NVARCHAR,
    "NVARCHAR2": TokenType.NVARCHAR,
    "STR": TokenType.TEXT,
    "STRING": TokenType.TEXT,
    "TEXT": TokenType.TEXT,
    "CLOB": TokenType.TEXT,
    "LONGVARCHAR": TokenType.TEXT,
    "BINARY": TokenType.BINARY,
    "BLOB": TokenType.VARBINARY,
    "BYTEA": TokenType.VARBINARY,
    "VARBINARY": TokenType.VARBINARY,
    "TIME": TokenType.TIME,
    "TIMESTAMP": TokenType.TIMESTAMP,
    "TIMESTAMPTZ": TokenType.TIMESTAMPTZ,
    "TIMESTAMPLTZ": TokenType.TIMESTAMPLTZ,
    "DATE": TokenType.DATE,
    "DATETIME": TokenType.DATETIME,
    "INT4RANGE": TokenType.INT4RANGE,
    "INT4MULTIRANGE": TokenType.INT4MULTIRANGE,
    "INT8RANGE": TokenType.INT8RANGE,
    "INT8MULTIRANGE": TokenType.INT8MULTIRANGE,
    "NUMRANGE": TokenType.NUMRANGE,
    "NUMMULTIRANGE": TokenType.NUMMULTIRANGE,
    "TSRANGE": TokenType.TSRANGE,
    "TSMULTIRANGE": TokenType.TSMULTIRANGE,
    "TSTZRANGE": TokenType.TSTZRANGE,
    "TSTZMULTIRANGE": TokenType.TSTZMULTIRANGE,
    "DATERANGE": TokenType.DATERANGE,
    "DATEMULTIRANGE": TokenType.DATEMULTIRANGE,
    "UNIQUE": TokenType.UNIQUE,
    "STRUCT": TokenType.STRUCT,
    "VARIANT": TokenType.VARIANT,
    "ALTER": TokenType.ALTER,
    "ANALYZE": TokenType.COMMAND,
    "CALL": TokenType.COMMAND,
    "COMMENT": TokenType.COMMENT,
    "COPY": TokenType.COMMAND,
    "EXPLAIN": TokenType.COMMAND,
    "GRANT": TokenType.COMMAND,
    "OPTIMIZE": TokenType.COMMAND,
    "PREPARE": TokenType.COMMAND,
    "TRUNCATE": TokenType.COMMAND,
    "VACUUM": TokenType.COMMAND,
};

const whiteSpace: WhitespaceConfig = {
    " ": TokenType.SPACE,
    "\t": TokenType.SPACE,
    "\n": TokenType.BREAK,
    "\r": TokenType.BREAK,
    "\r\n": TokenType.BREAK,
};

const commands: Array<TokenType> = [
    TokenType.COMMAND,
    TokenType.EXECUTE,
    TokenType.FETCH,
    TokenType.SHOW,
]


export const defaultTokenizerGrammar = TokenizerGrammar.TokenizerGrammarBuilder
    .getInstance()
    .setSingleTokens(singleTokens)
    .setIdentifiers(['"'])
    .setIdentifierEscapes(['"'])
    .setQuotes(["'"])
    .setStringEscapes(["'"])
    .setKeywords(keywords)
    .setWhiteSpace(whiteSpace)
    .setCommands(commands)
    .setCommandPrefixTokens([TokenType.SEMICOLON, TokenType.BEGIN])
    .setComments(["--", ["/*", "*/"]])
    .build();
